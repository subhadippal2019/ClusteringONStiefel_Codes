D[!upper.tri(D)]=9999
K=which(D<0.3&D!=0, arr.ind = TRUE)
n_merge = dim(K)[1]
proportion = MC$parameters$pro
for(id in 1:n_merge){
T[K[id,1]] = K[id,2]
}
}
T
which(T==-1)
update_phi <- function(y, d, phi_old){
nc = length(phi_old)
phi = rep(0,nc)
for(j in 1:nc){
if(sum(d==j) > 0){
phi[j] = mean(y[d==j])
}else{
phi[j] = phi_old[j]
}
}
return(phi)
}
update_z <- function(d,alpha,beta,z){
#nc = length(unique(d))
nc = length(z)
a = b = z = rep(0,nc)
for(j in 1:nc){
a[j] = alpha + sum(d==j)
b[j] = beta + sum(d>j)
z[j] = rbeta(1,a[j],b[j])
}
return(z)
}
compute_w_from_z <-function(z){
# compute w
mz = 1-z
w = z
if(length(z) > 1){
for (j in 2:length(z)){
w[j] = z[j]*prod(mz[1:(j-1)])
}
}else{
cat("**** only 1 cluster left *****\n")
}
return(w)
}
add_new_cluster <-function(nc,alpha=1,beta,s,z,mu){
z[nc] = rbeta(1,alpha,beta)
w = compute_w_from_z(z)
#cat("z = ",z,"\n")
mu[nc] = rnorm(1,0,1/s)
res = NULL
res$z = z
res$w = w
res$mu = mu
return(res)
}
# Main function-R
#y, maxiter, inc, s, alpha, beta
slice_DPM_Normal <- function(y,maxiter,nc,s,alpha,beta){
res = NULL
### j cluster index
### i data index
### y - 1xn vector, n is the number of data points
### n total number of data
### inc - the initial number of classes
### s - scaler for estimating mu, mu's prior is N(0,1/s)
### M - scaler hyperparameter for DP
## Initialization
n = length(y)
# number of classes
# sample z from beta(1,M)
z = rbeta(nc,alpha,beta)
w = compute_w_from_z(z)
# random initialize d_i
d = ceiling(nc*runif(n))
# initial mu
mu = rnorm(nc,0,1/s)  ### this is phi
## Main loop
for (iter in 1:maxiter) {
### sample phi
mu = update_phi(y,d,mu)
### sample z
z = update_z(d,alpha,beta,z) ### see Muller et al book
w = compute_w_from_z(z)
## sample u
u = runif(n)
for (i in 1:n){
u[i] = u[i]*w[d[i]]
}
## N = n
ustar = min(u)
while (sum(w[1:nc]) <= (1-ustar)){
nc = nc+1
#alpha = 0.1 to make the new cluster proportion small
res = add_new_cluster(nc,alpha,beta,s,z,mu)
cat("called adding new cluster \n")
z = res$z
w = res$w
mu = res$mu
}
#cat(length(w),"\t",length(mu),"\n")
## sample d
#browser()
for (i in 1:n){
w_greater_u_i = which(w > u[i])
L = length(w_greater_u_i)
pr_vec = rep(0,L)
for(l in 1:L){
k = w_greater_u_i[l]
pr_vec[l] = w[k]*dnorm(y[i],mu[k],1) ### variance is currently 1 + Normality assumption
}
#cat(pr_vec,"\n")
if(length(pr_vec) == 0){
cat("Error!!!!\n")
}
if(length(pr_vec) > 1){
d[i] = sample(w_greater_u_i,1,pr_vec,replace=FALSE)
}else{
d[i] = w_greater_u_i[1]
}
}
}
res$mu = mu
res$w = w
res$d = d
return(res)
}
#############################
set.seed(76583)
#############################
## data generation
N = 1000
pi_vec = c(0.2,0.2,0.2,0.2,0.2)
u = apply(rmultinom(N,1,pi_vec),2,function(x) which(x==1))
y = (u==1)*rnorm(N,3,1) + (u==2)*rnorm(N,-4,1) + (u==3)*rnorm(N,10,1) + (u==4)*rnorm(N,20,1) + (u==5)*rnorm(N,-10,1)
##############################
### initial clustering
library(mclust)
MC = Mclust(y,1)
#####################
### call slice sampler of DP
maxiter = 1000
inc = length(unique(MC$classification))
s = 0.03
alpha = 0.5
M = 1
beta = M
res = slice_DPM_Normal(y, maxiter, inc, s, alpha,beta)
id = as.integer(names(table(res$d)))
cat(res$mu[id],"\n")
cat(res$w[id],"\n")
print(table(res$d))
######################
#############################
set.seed(76583)
#############################
## data generation
N = 1000
pi_vec = c(0.2,0.2,0.2,0.2,0.2)
u = apply(rmultinom(N,1,pi_vec),2,function(x) which(x==1))
y = (u==1)*rnorm(N,3,1) + (u==2)*rnorm(N,-4,1) + (u==3)*rnorm(N,10,1) + (u==4)*rnorm(N,20,1) + (u==5)*rnorm(N,-10,1)
##############################
### initial clustering
library(mclust)
MC = Mclust(y,1)
#####################
### call slice sampler of DP
id_tmp = (u==3)
unif_sel = rbin(N,1,0.5)
id_3 = which(id_tmp*unif_sel==1)
id_4 = which(id_tmp*(1-unif_sel)==1)
id_tmp = (u==3)
unif_sel = rbinom(N,1,0.5)
id_3 = which(id_tmp*unif_sel==1)
id_4 = which(id_tmp*(1-unif_sel)==1)
id_3
id_4
length(id_3)
length(id_4)
set.seed(76583)
#############################
## data generation
N = 1000
pi_vec = c(0.2,0.2,0.2,0.2,0.2)
u = apply(rmultinom(N,1,pi_vec),2,function(x) which(x==1))
y = (u==1)*rnorm(N,3,1) + (u==2)*rnorm(N,-4,1) + (u==3)*rnorm(N,10,1) + (u==4)*rnorm(N,20,1) + (u==5)*rnorm(N,-10,1)
##############################
### initial clustering
library(mclust)
MC = Mclust(y,1)
MC$classification
id_tmp = (u==3)
unif_sel = rbinom(N,1,0.5)
id_3 = which(id_tmp*unif_sel==1)
id_4 = which(id_tmp*(1-unif_sel)==1)
MC$classification[id_3] = 2
MC$classification[id_4] = 3
MC$classification
maxiter = 500
inc = length(unique(MC$classification))
s = 0.03
alpha = 0.5
M = 1
beta = M
res = slice_DPM_Normal(y, maxiter, inc, s, alpha,beta)
id = as.integer(names(table(res$d)))
cat(res$mu[id],"\n")
cat(res$w[id],"\n")
print(table(res$d))
update_phi <- function(y, d, phi_old){
nc = length(phi_old)
phi = rep(0,nc)
for(j in 1:nc){
if(sum(d==j) > 0){
phi[j] = mean(y[d==j])
}else{
phi[j] = phi_old[j]
}
}
return(phi)
}
update_z <- function(d,alpha,beta,z){
#nc = length(unique(d))
nc = length(z)
a = b = z = rep(0,nc)
for(j in 1:nc){
a[j] = alpha + sum(d==j)
b[j] = beta + sum(d>j)
z[j] = rbeta(1,a[j],b[j])
}
return(z)
}
compute_w_from_z <-function(z){
# compute w
mz = 1-z
w = z
if(length(z) > 1){
for (j in 2:length(z)){
w[j] = z[j]*prod(mz[1:(j-1)])
}
}else{
cat("**** only 1 cluster left *****\n")
}
return(w)
}
add_new_cluster <-function(nc,alpha=1,beta,s,z,mu){
z[nc] = rbeta(1,alpha,beta)
w = compute_w_from_z(z)
#cat("z = ",z,"\n")
mu[nc] = rnorm(1,0,1/s)
res = NULL
res$z = z
res$w = w
res$mu = mu
return(res)
}
# Main function-R
#y, maxiter, inc, s, alpha, beta
slice_DPM_Normal <- function(y,maxiter,nc,s,alpha,beta){
res = NULL
### j cluster index
### i data index
### y - 1xn vector, n is the number of data points
### n total number of data
### inc - the initial number of classes
### s - scaler for estimating mu, mu's prior is N(0,1/s)
### M - scaler hyperparameter for DP
## Initialization
n = length(y)
# number of classes
# sample z from beta(1,M)
z = rbeta(nc,alpha,beta)
w = compute_w_from_z(z)
# random initialize d_i
d = ceiling(nc*runif(n))
# initial mu
mu = rnorm(nc,0,1/s)  ### this is phi
## Main loop
for (iter in 1:maxiter) {
### sample phi
mu = update_phi(y,d,mu)
### sample z
z = update_z(d,alpha,beta,z) ### see Muller et al book
w = compute_w_from_z(z)
## sample u
u = runif(n)
for (i in 1:n){
u[i] = u[i]*w[d[i]]
}
## N = n
ustar = min(u)
while (sum(w[1:nc]) <= (1-ustar)){
nc = nc+1
#alpha = 0.1 to make the new cluster proportion small
res = add_new_cluster(nc,alpha,beta,s,z,mu)
cat("called adding new cluster \n")
z = res$z
w = res$w
mu = res$mu
}
#cat(length(w),"\t",length(mu),"\n")
## sample d
#browser()
for (i in 1:n){
w_greater_u_i = which(w > u[i])
L = length(w_greater_u_i)
pr_vec = rep(0,L)
for(l in 1:L){
k = w_greater_u_i[l]
pr_vec[l] = w[k]*dnorm(y[i],mu[k],1) ### variance is currently 1 + Normality assumption
}
#cat(pr_vec,"\n")
if(length(pr_vec) == 0){
cat("Error!!!!\n")
}
if(length(pr_vec) > 1){
d[i] = sample(w_greater_u_i,1,pr_vec,replace=FALSE)
}else{
d[i] = w_greater_u_i[1]
}
}
}
res$mu = mu
res$w = w
res$d = d
return(res)
}
maxiter = 500
inc = length(unique(MC$classification))
s = 0.03
alpha = 0.5
M = 1
beta = M
res = slice_DPM_Normal(y, maxiter, inc, s, alpha,beta)
id = as.integer(names(table(res$d)))
cat(res$mu[id],"\n")
cat(res$w[id],"\n")
print(table(res$d))
######################
res$w
res$mu
y[id_4]
mean(y[id_4])
mean(y[id_3])
res$w
round(res$w,2)
res$mu
table(w)
table(res$w)
table(res$d)
res$w
res$mu[res$w > 0.0001]
res$mu[res$w > 0.01]
round(res$w,2)
table(res$d)
res$mu[round(res$w,2) > 0.01]
56.1111-4.92*(34/3)
56.1111-4.92*(11/3)
56.1111-(4.92*(34/3))
56.1111+(4.92*(34/3))
rgamma
C_rgamma
rnorm
tgamma
t=1.45
A=matrix(c(cos(t),sin(t),-sin(t),cos(t)),nrows=2)
A=matrix(c(cos(t),sin(t),-sin(t),cos(t)),nrow=2)
A
det(A)
eigen(A)
load("~/Dropbox/ClusteringDTIonstiefel/RealData/NEO/neo_192_data.RData")
neo_192
neo_192[,,1]
getwd("~/Dropbox/ClusteringDTIonstiefel/DensitySVD_sep1_16/")
.libPaths()
array(c(1,0,0,0,0,1,0,1,0,0,0,-1,0,0,1,1,0,0), c(3, 2, 3))
Sys.time()
Sys.time()
Sys.time()
system.time()
setwd("~/Dropbox/ClusteringDTIonstiefel/DensitySVD_sep1_16/")
grp_id = 1
src_name = sprintf("./vcg_data/vcg_output_group%d_McFee.RData",grp_id)
load(src_name)
T=data_with_init_with_MCMC_samples$MCMC_sample[[1000]]$curr_param
T$M%*%T$D%*%T$V
T$M%*%T$D%*%t(T$V)
T$M
T$D
T$V
T$M%*%T$D%*%(T$V)
T$M%*%T$D
dim(T$M)
as.matrix(T$M)
as.matrix(T$M,nrow=3)
matrix(T$M,nrow=3)
T$M
M=matrix(T$M,nrow=3)
D=matrix(T$D,nrow=2)
V=matrix(T$V,nrow=2)
M
D
V
T$V
M%*%D%*%V
T$F
M%*%D%*%t(V)
grp_id = 1
src_name = sprintf("./vcg_data/vcg_output_group%d_McFee.RData",grp_id)
i=1
T=data_with_init_with_MCMC_samples$MCMC_sample[[i]]$curr_param
M=matrix(T$M,nrow=3)
D=matrix(T$D,nrow=2)
V=matrix(T$V,nrow=2)
grp_id = 1
src_name = sprintf("./vcg_data/vcg_output_group%d_McFee.RData",grp_id)
load(src_name)
i=1
T=data_with_init_with_MCMC_samples$MCMC_sample[[i]]$curr_param
M=matrix(T$M,nrow=3)
D=matrix(T$D,nrow=2)
V=matrix(T$V,nrow=2)
V
as.vector(V)
as.vector(t(V))
v1=as.vector(V)
v2=as.vector(t(V))
sum(v1-v2)
v1==v2
any(v1==v2)
any(v1!=v2)
any(V!=t(V))
i=1000
T=data_with_init_with_MCMC_samples$MCMC_sample[[i]]$curr_param
M=matrix(T$M,nrow=3)
D=matrix(T$D,nrow=2)
V=matrix(T$V,nrow=2)
any(V!=t(V))
V
t(V)
V==t(V)
v1=as.vector(V)
v2=as.vector(t(V))
v1
v2
v1-v2
grp_id = 1
src_name = sprintf("./vcg_data/vcg_output_group%d_McFee.RData",grp_id)
load(src_name)
i=1
T=data_with_init_with_MCMC_samples$MCMC_sample[[i]]$curr_param
M=matrix(T$M,nrow=3)
D=matrix(T$D,nrow=2)
V=matrix(T$V,nrow=2)
T$F
M%*%D%*%V
M%*%D%*%t(V)
load("./vcg_data/vcg_output_group1.RData")
apply(data_with_init_with_MCMC_samples$data,c(1,2),mean)
load("./vcg_data/vcg_output_group3.RData")
apply(data_with_init_with_MCMC_samples$data,c(1,2),mean)
load("./vcg_data/vcg_output_group3_McFee.RData")
apply(data_with_init_with_MCMC_samples$data,c(1,2),mean)
load("./vcg_data/vcg_output_group1_McFee.RData")
apply(data_with_init_with_MCMC_samples$data,c(1,2),mean)
###########
### utility functions
#' It is a debug print function
#' @param str = input string
#' @param debug_flag = boolean flag to print or not
#' @return NULL
print_debug <-function(str,debug_flag){
if(debug_flag == 1){
print(str)
}
}
err_msg <-function(str){
print(paste0('***********ERROR*************'))
print(str)
print(paste0('***********ERROR*************'))
}
load_src_libs <-function()
{
require(rstiefel)
require(gtools)
require(expm)
require(MASS)
source("cluster_param_update.R")
source("rdensity_d1_d2.R")
source("NR_method_d1.R")
source("analyse_MCMC_sample.R")
source("bivariate_NR_method_d1_d2.R")
source("stiefel_SVD.R")
#source("utility.R")
source("preprocess_data.R")
source("generate_simulated_data_ML.R")
source("finiteMixtureML.R")
library(gsl)
library(Rcpp)
sourceCpp('C:/Users/subha/Dropbox/projects/ClusteringDTIonStiefel/DensitySVD_sep1_16/package_code/src/functions_hyper_2by2_CPP.cpp')
#dyn.load("./src/functions_hyper_2by2_R.so")
}
#### DIC calculation function
load_src_libs()
hyper_2by2_R_test(1.5,c(5,q))
hyper_2by2_R_test(1.5,c(5,1))
plot(hyper_2by2_R_test(1.5,c(5,1)))
plot(hyper_2by2_R_test(2.5,c(5,1)))
plot(hyper_2by2_R_test(10.5,c(5,1)))
(hyper_2by2_R_test(10.5,c(5,1)))
(hyper_2by2_R_test(1.5,c(5,1)))
